{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, plot_roc_curve, roc_curve\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "from scipy.stats import ttest_ind\n",
    "from mne.viz import circular_layout, plot_connectivity_circle\n",
    "% matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data\n",
    "\n",
    "labels: a file including 0 or 1 for each participant\n",
    "\n",
    "features: a matrix in which each row is a participant, and each column is a feature. in this study, features are edges of a functional connectome, derived from the Schafer 7_networks_100_parcels parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('path_to_labels_file', sep='\\n', header=None).squeeze()\n",
    "\n",
    "features = pd.read_csv('path_to_features_file', index_col=0, header=0)\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "features = pd.DataFrame(data = scaler.fit_transform(features), index=features.index, columns=features.columns)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit model to optimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "log_lambda = np.linspace(3,-3,101)\n",
    "C = 1/np.exp(log_lambda)\n",
    "l1_ratios=np.linspace(0.7,1,7)\n",
    "clf = LogisticRegressionCV(Cs=C,penalty='elasticnet',solver='saga', l1_ratios=l1_ratios,cv=kfold, scoring=\"roc_auc\")\n",
    "results = clf.fit(features, labels)\n",
    "scores = results.scores_[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_l1_ratio = results.l1_ratio_[0]\n",
    "print(f'best l1_ratio is: {best_l1_ratio}')\n",
    "best_l1_loc = np.where(l1_ratios==best_l1_ratio)[0][0]\n",
    "scores_2d = scores[:,:,best_l1_loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_auc = np.mean(scores_2d, axis=0)\n",
    "standard_deviations = np.std(scores_2d, axis=0)\n",
    "standard_errors = standard_deviations / np.sqrt(10)\n",
    "figure = plt.figure(figsize=(15, 5))\n",
    "axes = figure.add_subplot(111)\n",
    "axes.set_xlabel('ln(Î»)')\n",
    "axes.set_ylabel('AUC')\n",
    "plt.errorbar(x=log_lambda, y=mean_auc, yerr=standard_errors)\n",
    "plt.title('roc-auc scores for depending on regularization strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_lambda = -0.25 # determined by the plot\n",
    "best_C = 1/np.exp(best_log_lambda)\n",
    "best_l1_ratio=0.7\n",
    "print(f'best log_lambda: {best_log_lambda}, best C: {best_C}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions for finding optimal threshold through ROC\n",
    "\n",
    "def find_optimal_cutoff(target, predicted):\n",
    "  # finds the optimal threshold from the ROC-curve\n",
    "  fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "  i = np.arange(len(tpr)) \n",
    "  roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "  roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "  return roc_t['threshold'].values[0]\n",
    "\n",
    "def calc_precision(proba, Y_test, thresh, to_print=False):\n",
    "  # calcultes the presicion of a model, given the prediction probabilities for each subject\n",
    "  # set plot=True to plot the two populations' prediction probabilites\n",
    "  proba = np.array(proba)\n",
    "  predict_proba = proba>=thresh\n",
    "  tn, fp, fn, tp = confusion_matrix(Y_test, predict_proba).ravel()\n",
    "  accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "  sensitivity = tp / (tp+fn)\n",
    "  specificity = tn / (tn+fp)\n",
    "  if to_print:\n",
    "    print(f'accuracy: {accuracy}\\nsensitivity: {sensitivity}\\nspecificity: {specificity}')\n",
    "  return accuracy, sensitivity, specificity\n",
    "\n",
    "def get_measures_by_kfold(features, labels, to_plot=False):\n",
    "  kfold=StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "  clf = LogisticRegression(penalty='elasticnet', l1_ratio=best_l1_ratio, C=best_C, solver='saga', random_state=42)\n",
    "  aucs = []\n",
    "  accuracies = []\n",
    "  sensitivities = []\n",
    "  specificities = []\n",
    "  if to_plot:\n",
    "    fig, ax = plt.subplots()\n",
    "  for fold, (train_index, test_index) in enumerate(kfold.split(features, labels)):\n",
    "      X_train, X_test = features.iloc[train_index,:], features.iloc[test_index,:]\n",
    "      Y_train, Y_test = labels[train_index], labels[test_index]\n",
    "      clf.fit(X_train, Y_train)\n",
    "      proba = clf.predict_proba(X_test)[:,1]\n",
    "      aucs.append(roc_auc_score(Y_test, proba))\n",
    "      optimal_thresh = find_optimal_cutoff(Y_test, proba)\n",
    "      accuracy, sensitivity, specificity = calc_precision(proba, Y_test, optimal_thresh)\n",
    "      accuracies.append(accuracy)\n",
    "      sensitivities.append(sensitivity)\n",
    "      specificities.append(specificity)\n",
    "      if to_plot:\n",
    "          plot_roc_curve(clf, X_test, Y_test,\n",
    "                         name=f'ROC fold {fold+1}',\n",
    "                         alpha=0.4, lw=3, ax=ax, linewidth=2)\n",
    "          plt.plot([0,1],[0,1], color='black', linestyle='--')\n",
    "  return np.mean(aucs), np.mean(accuracies), np.mean(sensitivities), np.mean(specificities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc, accuracy, sensitivity, specificity = get_measures_by_kfold(features, labels, 1)\n",
    "print(f'auc: {auc}\\naccuracy: {accuracy}\\nsensitivity: {sensitivity}\\nspecificity: {specificity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(features, labels, test_size=0.5, random_state=0, stratify=labels)\n",
    "\n",
    "clf=LogisticRegression(penalty='elasticnet', l1_ratio=best_l1_ratio, C=best_C, solver='saga').fit(X_train, y_train)\n",
    "auc_perm_scores = []\n",
    "accuracy_perm_scores = []\n",
    "sensitivity_perm_scores = []\n",
    "specificity_perm_scores = []\n",
    "test_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# first we calc the real values\n",
    "optimal_threshold = find_optimal_cutoff(y_test, test_pred_proba)\n",
    "accuracy, sensitivity, specificity = calc_precision(test_pred_proba, y_test, optimal_threshold)\n",
    "auc = roc_auc_score(y_test, test_pred_proba)\n",
    "auc_perm_scores.append(auc)\n",
    "accuracy_perm_scores.append(accuracy)\n",
    "sensitivity_perm_scores.append(sensitivity)\n",
    "specificity_perm_scores.append(specificity)\n",
    "\n",
    "# define a shuffling function\n",
    "\n",
    "def shuffle_copy(to_shuffle):\n",
    "  # returns shuffled DataFrame to utilize in permutation tests\n",
    "  shuffled = to_shuffle.copy()\n",
    "  shuffled = shuffled.values\n",
    "  np.random.shuffle(shuffled)\n",
    "  return shuffled\n",
    "\n",
    "# now run the permutations\n",
    "\n",
    "n_perm = 5000\n",
    "for n in range(n_perm-1):\n",
    "  shuffled_labels = shuffle_copy(y_test)\n",
    "  optimal_threshold = find_optimal_cutoff(shuffled_labels, test_pred_proba)\n",
    "  accuracy, sensitivity, specificity = calc_precision(test_pred_proba, shuffled_labels, optimal_threshold)\n",
    "  auc = roc_auc_score(shuffled_labels, test_pred_proba)\n",
    "  auc_perm_scores.append(auc)\n",
    "  accuracy_perm_scores.append(accuracy)\n",
    "  sensitivity_perm_scores.append(sensitivity)\n",
    "  specificity_perm_scores.append(specificity)\n",
    "\n",
    "permutation_df = pd.DataFrame(data=zip(auc_perm_scores,accuracy_perm_scores,sensitivity_perm_scores,specificity_perm_scores), columns=['AUC', 'Accuracy', 'Sensitivity', 'Specificity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate significance\n",
    "\n",
    "def get_significance_perm(df,param):\n",
    "  # calculate significance for permutation scores. assumes the true scores are the first in the data\n",
    "  perm_scores = df[param]\n",
    "  true_score = perm_scores[0]\n",
    "  greater_eq_than = sum(perm_scores>=true_score)\n",
    "  return round(greater_eq_than/len(perm_scores),4)\n",
    "\n",
    "print('permutation test significance:\\n')\n",
    "for param in permutation_df.columns:\n",
    "  print(f'{param} permutation scores: {get_significance_perm(permutation_df, param)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get beta values using mean of 1000 iterations\n",
    "\n",
    "n_iters_coeff = 1000\n",
    "coefs= np.zeros((n_iters_coeff,features.shape[1]))\n",
    "for n in range(n_iters_coeff):\n",
    "  print(n)\n",
    "  clf = LogisticRegression(penalty='elasticnet', l1_ratio=best_l1_ratio, C=best_C, solver='saga')\n",
    "  clf.fit(features, labels)\n",
    "  coefs[n,:] = clf.coef_.flatten()\n",
    "coef=np.mean(coefs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for plotting\n",
    "dyads = []\n",
    "for i in range(len(features.columns)):\n",
    "  feat_data = features.columns[i].split('--X--')\n",
    "  feat_data.append(coef[i])\n",
    "  dyads.append(feat_data)\n",
    "features_beta_df = pd.DataFrame(dyads, columns=['feature_1', 'feature_2', 'beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names = list(features_beta_df.feature_1) + list(features_beta_df.feature_2)\n",
    "node_names = list(set(node_names))\n",
    "con = np.abs(coef)\n",
    "\n",
    "i_1 = []\n",
    "i_2 = []\n",
    "for f in range(len(features_beta_df)):\n",
    "  feature = features_beta_df.iloc[f,:]\n",
    "  i_1.append(node_names.index(feature['feature_1']))\n",
    "  i_2.append(node_names.index(feature['feature_2']))\n",
    "indices = (np.array(i_1), np.array(i_2))\n",
    "\n",
    "lh_names = [name for name in node_names if 'LH' in name]\n",
    "rh_names = [name for name in node_names if 'RH' in name]\n",
    "lh_ordered = []\n",
    "rh_ordered = []\n",
    "net_names = ['Vis', 'SomMot', 'DorsAttn', 'SalVentAttn', 'Limbic', 'Cont', 'Default']\n",
    "for network in net_names: \n",
    "  lh_net_names = [name for name in lh_names if network in name]\n",
    "  lh_ordered = lh_ordered + lh_net_names\n",
    "\n",
    "  rh_net_names = [name for name in rh_names if network in name]\n",
    "  rh_ordered = rh_ordered + rh_net_names\n",
    "lh_ordered.reverse()\n",
    "ordered = lh_ordered + rh_ordered\n",
    "\n",
    "layout = circular_layout(node_names=node_names, node_order=ordered, group_boundaries=[0, len(lh_ordered)])\n",
    "colors_list = ['purple', 'blue', 'green', 'violet', 'wheat', 'orange', 'red']\n",
    "#colors_list = [(120/255, 18/255, 133/255), (70/255, 130/255, 180/255), (0/255, 118/255, 14/255), (196/255, 57/255, 248/255), (220/255, 248/255, 162/255), (230/255, 146/255, 32/255), (204/255, 60/255, 78/255)]\n",
    "\n",
    "color_dict = dict(zip(net_names, colors_list))\n",
    "node_colors = []\n",
    "for name in node_names:\n",
    "  net = name.split('_')[2]\n",
    "  node_colors.append(color_dict[net])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
